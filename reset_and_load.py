import os
import sys
import re
import time
import datetime as dt
import pandas as pd
from sqlalchemy import create_engine, text
from dotenv import load_dotenv

# éœ€è¦ï¼šakshare, pandas, sqlalchemy, psycopg2-binary, python-dotenv, openpyxl
import akshare as ak

load_dotenv()
DB_URL = os.getenv("DB_URL")
if not DB_URL:
    print("è¯·åœ¨ .env é‡Œè®¾ç½® DB_URL")
    sys.exit(1)

engine = create_engine(DB_URL, future=True)

# ============ è§„èŒƒåŒ–ä¸æ ¡éªŒ ============
DIGITS6 = re.compile(r"^\d{1,6}$")

def fix_code_to_6digits(raw: str) -> str | None:
    s = str(raw).strip().upper().replace('.SZSE','').replace('.SSE','')
    if '.' in s and len(s.split('.')[0]) == 6:
        code6, suf = s.split('.', 1)
        if not code6.isdigit(): return None
        if suf not in ('SH','SZ','BJ'): return None
        return f"{code6}.{suf}"
    digits = re.sub(r"\D", "", s)
    if not digits or not DIGITS6.match(digits):
        return None
    code6 = digits.zfill(6)
    if code6[0] == '6': return f"{code6}.SH"
    if code6[0] in ('0','3'): return f"{code6}.SZ"
    if code6[0] in ('8','4'): return f"{code6}.BJ"
    return None

def ak_symbol(sec_code: str) -> str:
    return sec_code.split('.')[0]

def parse_date(s: str) -> dt.date:
    s = str(s).strip().replace('/','-').replace('.','-')
    return dt.datetime.strptime(s, "%Y-%m-%d").date()

# ============ å»ºè¡¨ ============
DDL = """
CREATE TABLE IF NOT EXISTS ref_list (
  sec_code      VARCHAR(12) PRIMARY KEY,
  sec_name      VARCHAR(64),
  pick_dates    TEXT NOT NULL,   -- è®°å½•æ¯æ®µçš„â€œé¦–ä¸ªå…¥é€‰æ—¥â€ï¼Œå¤šä¸ªæ®µç”¨é€—å·åˆ†éš”
  streaks       TEXT,            -- ä¸ pick_dates å¯¹åº”çš„æ®µå†…è¿ç»­å¤©æ•°
  updated_at    TIMESTAMP DEFAULT NOW()
);

CREATE TABLE IF NOT EXISTS stock_info (
  sec_code      VARCHAR(12) PRIMARY KEY,
  sec_name      VARCHAR(64) NOT NULL,
  float_mktcap_100m NUMERIC(20,2),
  updated_at    TIMESTAMP DEFAULT NOW()
);

CREATE TABLE IF NOT EXISTS stock_window (
  sec_code      VARCHAR(12) NOT NULL,
  pick_date     DATE NOT NULL,
  o_m3 NUMERIC(18,4), c_m3 NUMERIC(18,4), pctc_m3 NUMERIC(10,4), pcto_m3 NUMERIC(10,4), amp_m3 NUMERIC(10,4), turn_m3 NUMERIC(10,4), amt_m3 NUMERIC(20,2),
  o_m2 NUMERIC(18,4), c_m2 NUMERIC(18,4), pctc_m2 NUMERIC(10,4), pcto_m2 NUMERIC(10,4), amp_m2 NUMERIC(10,4), turn_m2 NUMERIC(10,4), amt_m2 NUMERIC(20,2),
  o_m1 NUMERIC(18,4), c_m1 NUMERIC(18,4), pctc_m1 NUMERIC(10,4), pcto_m1 NUMERIC(10,4), amp_m1 NUMERIC(10,4), turn_m1 NUMERIC(10,4), amt_m1 NUMERIC(20,2),
  o_d0 NUMERIC(18,4), c_d0 NUMERIC(18,4), pctc_d0 NUMERIC(10,4), pcto_d0 NUMERIC(10,4), amp_d0 NUMERIC(10,4), amt_d0 NUMERIC(20,2), turn_d0 NUMERIC(10,4),
  o_p1 NUMERIC(18,4), c_p1 NUMERIC(18,4), pctc_p1 NUMERIC(10,4), pcto_p1 NUMERIC(10,4), amp_p1 NUMERIC(10,4), turn_p1 NUMERIC(10,4), amt_p1 NUMERIC(20,2),
  o_p2 NUMERIC(18,4), c_p2 NUMERIC(18,4), pctc_p2 NUMERIC(10,4), pcto_p2 NUMERIC(10,4), amp_p2 NUMERIC(10,4), turn_p2 NUMERIC(10,4), amt_p2 NUMERIC(20,2),
  o_p3 NUMERIC(18,4), c_p3 NUMERIC(18,4), pctc_p3 NUMERIC(10,4), pcto_p3 NUMERIC(10,4), amp_p3 NUMERIC(10,4), turn_p3 NUMERIC(10,4), amt_p3 NUMERIC(20,2),
  updated_at    TIMESTAMP DEFAULT NOW(),
  PRIMARY KEY (sec_code, pick_date)
);

CREATE INDEX IF NOT EXISTS idx_window_date ON stock_window(pick_date);
"""

def ensure_tables():
    with engine.begin() as conn:
        conn.execute(text(DDL))

# ============ è¯»å– Excel ============
def read_picks(excel_path: str) -> pd.DataFrame:
    if excel_path.lower().endswith('.csv'):
        df = pd.read_csv(excel_path)
    else:
        df = pd.read_excel(excel_path)
    df.columns = [c.strip().lower() for c in df.columns]
    if not {'pick_date','code'}.issubset(df.columns):
        raise ValueError("Excel/CSV éœ€åŒ…å«åˆ—ï¼špick_date, code")
    df['sec_code'] = df['code'].apply(fix_code_to_6digits)
    df['pick_date'] = df['pick_date'].apply(parse_date)
    bad = df[df['sec_code'].isna()]
    if not bad.empty:
        print("âš ï¸ å‘ç°æ— æ•ˆä»£ç ï¼ˆå·²è·³è¿‡ï¼‰æ¡æ•°ï¼š", len(bad))
        print("ç¤ºä¾‹ï¼š", bad.head(10).to_dict(orient='records'))
    df = df[df['sec_code'].notna()]
    df = df[['sec_code','pick_date']].drop_duplicates().sort_values(['sec_code','pick_date'])
    return df

# ============ åˆ†æ®µ ============
def episodes_from_dates(dates: list[dt.date]) -> tuple[list[dt.date], list[int]]:
    if not dates: return [], []
    starts, streaks = [], []
    cur_start, cur_len = dates[0], 1
    prev = dates[0]
    for d in dates[1:]:
        if (d - prev).days <= 7:
            cur_len += 1
        else:
            starts.append(cur_start); streaks.append(cur_len)
            cur_start, cur_len = d, 1
        prev = d
    starts.append(cur_start); streaks.append(cur_len)
    return starts, streaks

def build_ref_list(df_picks: pd.DataFrame) -> pd.DataFrame:
    out = []
    for sec, g in df_picks.groupby('sec_code'):
        ds = sorted(g['pick_date'].tolist())
        starts, streaks = episodes_from_dates(ds)
        out.append({
            'sec_code': sec,
            'sec_name': None,
            'pick_dates': ','.join(d.strftime('%Y-%m-%d') for d in starts),
            'streaks': ','.join(str(x) for x in streaks)
        })
    return pd.DataFrame(out)

# ============ åç§°/å¸‚å€¼ï¼ˆå¸¦é‡è¯•ï¼‰ ============
def fetch_name_mktcap(sym: str, max_retry: int = 3, sleep_sec: float = 0.6):
    last_err = None
    for _ in range(max_retry):
        try:
            info = ak.stock_individual_info_em(sym)
            if info is not None and isinstance(info, pd.DataFrame) and not info.empty:
                if info.shape[1] >= 2:
                    info = info.iloc[:, :2].copy()
                    info.columns = ['item','value']
                    kv = dict(zip(info['item'], info['value']))
                    name = kv.get('è¯åˆ¸ç®€ç§°') or kv.get('è‚¡ç¥¨ç®€ç§°') or kv.get('ç®€ç§°')
                    v = kv.get('æµé€šå¸‚å€¼(å…ƒ)') or kv.get('æµé€šå¸‚å€¼')
                    if isinstance(v, str):
                        v = float(v.replace(',', '').replace('å…ƒ','').strip() or 0)
                    cap100m = (v/1e8) if v else None
                    return name, cap100m
            return None, None
        except Exception as e:
            last_err = e
            time.sleep(sleep_sec)
    if last_err:
        print(f"[{sym}] è·å–åç§°/å¸‚å€¼å¤±è´¥ï¼š{last_err}")
    return None, None

def fill_names_and_mktcap(ref_df: pd.DataFrame) -> pd.DataFrame:
    names, caps = [], []
    for sec in ref_df['sec_code']:
        name, cap = fetch_name_mktcap(ak_symbol(sec))
        names.append(name); caps.append(cap)
    ref_df = ref_df.copy()
    ref_df['sec_name'] = names
    with engine.begin() as conn:
        upsert_b = text("""
            INSERT INTO stock_info (sec_code, sec_name, float_mktcap_100m)
            VALUES (:sec, :name, :cap)
            ON CONFLICT (sec_code) DO UPDATE
            SET sec_name = COALESCE(EXCLUDED.sec_name, stock_info.sec_name),
                float_mktcap_100m = COALESCE(EXCLUDED.float_mktcap_100m, stock_info.float_mktcap_100m),
                updated_at = NOW();
        """)
        for sec, name, cap in zip(ref_df['sec_code'], ref_df['sec_name'], caps):
            conn.execute(upsert_b, {'sec': sec, 'name': name or '', 'cap': cap})
    return ref_df

def save_ref_list(ref_df: pd.DataFrame):
    with engine.begin() as conn:
        upsert = text("""
            INSERT INTO ref_list (sec_code, sec_name, pick_dates, streaks)
            VALUES (:sec, :name, :dates, :streaks)
            ON CONFLICT (sec_code) DO UPDATE
            SET sec_name = COALESCE(EXCLUDED.sec_name, ref_list.sec_name),
                pick_dates = EXCLUDED.pick_dates,
                streaks = EXCLUDED.streaks,
                updated_at = NOW();
        """)
        for _, r in ref_df.iterrows():
            conn.execute(upsert, {
                'sec': r['sec_code'],
                'name': r['sec_name'] if pd.notna(r['sec_name']) else None,
                'dates': r['pick_dates'],
                'streaks': r['streaks']
            })
    print(f"âœ… å·²å†™å…¥ Aè¡¨ ref_listï¼š{len(ref_df)} æ¡")

# ============ äº¤æ˜“æ—¥çª—å£ï¼šæŒ‰â€œäº¤æ˜“æ—¥ç´¢å¼•â€å– T-3~T+3 ============
def fetch_hist_df(sec_code: str, start: dt.date, end: dt.date) -> pd.DataFrame:
    sym = ak_symbol(sec_code)
    try:
        df = ak.stock_zh_a_hist(
            symbol=sym, period="daily",
            start_date=start.strftime("%Y%m%d"),
            end_date=end.strftime("%Y%m%d"),
            adjust="qfq"
        )
    except Exception:
        return pd.DataFrame()
    if df is None or not isinstance(df, pd.DataFrame) or df.empty:
        return pd.DataFrame()

    mapping = {
        "æ—¥æœŸ":"date","å¼€ç›˜":"open","æœ€é«˜":"high","æœ€ä½":"low","æ”¶ç›˜":"close",
        "æ¶¨è·Œå¹…":"pct_chg","æŒ¯å¹…":"amplitude","æˆäº¤é‡":"volume","æˆäº¤é¢":"amount",
        "æ¢æ‰‹ç‡":"turnover_rate","é‡æ¯”":"volume_ratio","å‰æ”¶ç›˜":"pre_close"
    }
    for cn,en in mapping.items():
        if cn in df.columns: df.rename(columns={cn:en}, inplace=True)
    if "date" not in df.columns and "æ—¥æœŸ" in df.columns:
        df.rename(columns={"æ—¥æœŸ":"date"}, inplace=True)

    df["date"] = pd.to_datetime(df["date"], errors="coerce").dt.date
    df = df[pd.notna(df["date"])].sort_values("date")
    if df.empty: return pd.DataFrame()

    if "pre_close" not in df.columns or df["pre_close"].isna().all():
        df["pre_close"] = df["close"].shift(1)
    if "pct_chg" not in df.columns or df["pct_chg"].isna().all():
        df["pct_chg"] = (df["close"] / df["pre_close"] - 1.0) * 100
    if "amplitude" not in df.columns or df["amplitude"].isna().all():
        df["amplitude"] = (df["high"] - df["low"]) / df["pre_close"] * 100
    df["pcto"] = (df["open"] / df["pre_close"] - 1.0) * 100
    return df

def pick_by_trade_offset(hist: pd.DataFrame, t: dt.date, delta: int):
    """
    åœ¨ hist çš„äº¤æ˜“æ—¥åºåˆ—é‡Œï¼šæ‰¾åˆ°æ—¥æœŸ t çš„ç´¢å¼• iï¼Œè¿”å› i+delta é‚£å¤©çš„æŒ‡æ ‡ã€‚
    è‹¥ t ä¸åœ¨ histï¼ˆæå°‘è§ï¼Œæˆ– Excel ç»™äº†ä¼‘å¸‚æ—¥ï¼‰ï¼Œåˆ™è¿”å›ç©ºã€‚
    """
    dates = hist["date"].tolist()
    try:
        i = dates.index(t)
    except ValueError:
        return (None,)*7
    j = i + delta
    if j < 0 or j >= len(dates):
        return (None,)*7
    r = hist.iloc[j]
    return (
        float(r.get('open')) if pd.notna(r.get('open')) else None,
        float(r.get('close')) if pd.notna(r.get('close')) else None,
        float(r.get('pct_chg')) if pd.notna(r.get('pct_chg')) else None,
        float(r.get('pcto')) if pd.notna(r.get('pcto')) else None,
        float(r.get('amplitude')) if pd.notna(r.get('amplitude')) else None,
        float(r.get('turnover_rate')) if pd.notna(r.get('turnover_rate')) else None,
        float(r.get('amount')) if pd.notna(r.get('amount')) else None,
    )

def fill_stock_window_from_ref(ref_df: pd.DataFrame):
    with engine.begin() as conn:
        upsert = text("""
            INSERT INTO stock_window (
              sec_code, pick_date,
              o_m3,c_m3,pctc_m3,pcto_m3,amp_m3,turn_m3,amt_m3,
              o_m2,c_m2,pctc_m2,pcto_m2,amp_m2,turn_m2,amt_m2,
              o_m1,c_m1,pctc_m1,pcto_m1,amp_m1,turn_m1,amt_m1,
              o_d0,c_d0,pctc_d0,pcto_d0,amp_d0,amt_d0,turn_d0,
              o_p1,c_p1,pctc_p1,pcto_p1,amp_p1,turn_p1,amt_p1,
              o_p2,c_p2,pctc_p2,pcto_p2,amp_p2,turn_p2,amt_p2,
              o_p3,c_p3,pctc_p3,pcto_p3,amp_p3,turn_p3,amt_p3
            ) VALUES (
              :sec, :t,
              :o_m3,:c_m3,:pctc_m3,:pcto_m3,:amp_m3,:turn_m3,:amt_m3,
              :o_m2,:c_m2,:pctc_m2,:pcto_m2,:amp_m2,:turn_m2,:amt_m2,
              :o_m1,:c_m1,:pctc_m1,:pcto_m1,:amp_m1,:turn_m1,:amt_m1,
              :o_d0,:c_d0,:pctc_d0,:pcto_d0,:amp_d0,:amt_d0,:turn_d0,
              :o_p1,:c_p1,:pctc_p1,:pcto_p1,:amp_p1,:turn_p1,:amt_p1,
              :o_p2,:c_p2,:pctc_p2,:pcto_p2,:amp_p2,:turn_p2,:amt_p2,
              :o_p3,:c_p3,:pctc_p3,:pcto_p3,:amp_p3,:turn_p3,:amt_p3
            )
            ON CONFLICT (sec_code, pick_date) DO UPDATE SET
              o_m3=EXCLUDED.o_m3, c_m3=EXCLUDED.c_m3, pctc_m3=EXCLUDED.pctc_m3, pcto_m3=EXCLUDED.pcto_m3, amp_m3=EXCLUDED.amp_m3, turn_m3=EXCLUDED.turn_m3, amt_m3=EXCLUDED.amt_m3,
              o_m2=EXCLUDED.o_m2, c_m2=EXCLUDED.c_m2, pctc_m2=EXCLUDED.pctc_m2, pcto_m2=EXCLUDED.pcto_m2, amp_m2=EXCLUDED.amp_m2, turn_m2=EXCLUDED.turn_m2, amt_m2=EXCLUDED.amt_m2,
              o_m1=EXCLUDED.o_m1, c_m1=EXCLUDED.c_m1, pctc_m1=EXCLUDED.pctc_m1, pcto_m1=EXCLUDED.pcto_m1, amp_m1=EXCLUDED.amp_m1, turn_m1=EXCLUDED.turn_m1, amt_m1=EXCLUDED.amt_m1,
              o_d0=EXCLUDED.o_d0, c_d0=EXCLUDED.c_d0, pctc_d0=EXCLUDED.pctc_d0, pcto_d0=EXCLUDED.pcto_d0, amp_d0=EXCLUDED.amp_d0, amt_d0=EXCLUDED.amt_d0, turn_d0=EXCLUDED.turn_d0,
              o_p1=EXCLUDED.o_p1, c_p1=EXCLUDED.c_p1, pctc_p1=EXCLUDED.pctc_p1, pcto_p1=EXCLUDED.pcto_p1, amp_p1=EXCLUDED.amp_p1, turn_p1=EXCLUDED.turn_p1, amt_p1=EXCLUDED.amt_p1,
              o_p2=EXCLUDED.o_p2, c_p2=EXCLUDED.c_p2, pctc_p2=EXCLUDED.pctc_p2, pcto_p2=EXCLUDED.pcto_p2, amp_p2=EXCLUDED.amp_p2, turn_p2=EXCLUDED.turn_p2, amt_p2=EXCLUDED.amt_p2,
              o_p3=EXCLUDED.o_p3, c_p3=EXCLUDED.c_p3, pctc_p3=EXCLUDED.pctc_p3, pcto_p3=EXCLUDED.pcto_p3, amp_p3=EXCLUDED.amp_p3, turn_p3=EXCLUDED.turn_p3, amt_p3=EXCLUDED.amt_p3,
              updated_at = NOW();
        """)

        for _, r in ref_df.iterrows():
            sec = r['sec_code']
            ep_starts = [dt.datetime.strptime(x, "%Y-%m-%d").date()
                         for x in str(r['pick_dates']).split(',') if x.strip()]
            if not ep_starts:
                continue

            start = min(ep_starts) - dt.timedelta(days=30)
            end   = max(ep_starts) + dt.timedelta(days=30)
            hist = fetch_hist_df(sec, start, end)
            if hist.empty:
                print(f"[{sec}] æ— å†å²æ•°æ®ï¼Œè·³è¿‡")
                continue

            for t in ep_starts:
                payload = {'sec': sec, 't': t}
                # ç”¨â€œäº¤æ˜“æ—¥åç§»â€æ–¹å¼æŠ“ T-3~T+3ï¼ˆè‡ªåŠ¨è·³è¿‡å‘¨æœ«/ä¼‘å¸‚ï¼‰
                for suf, delta in [('m3',-3),('m2',-2),('m1',-1),('d0',0),('p1',1),('p2',2),('p3',3)]:
                    o,c,pctc,pcto,amp,turn,amt = pick_by_trade_offset(hist, t, delta)
                    payload[f"o_{suf}"]=o; payload[f"c_{suf}"]=c
                    payload[f"pctc_{suf}"]=pctc; payload[f"pcto_{suf}"]=pcto
                    payload[f"amp_{suf}"]=amp; payload[f"turn_{suf}"]=turn; payload[f"amt_{suf}"]=amt
                conn.execute(upsert, payload)
    print("âœ… å·²å†™å…¥ Cè¡¨ stock_windowï¼ˆæŒ‰äº¤æ˜“æ—¥ç´¢å¼•ï¼‰")

# ============ è¿è¡Œåæ ¡éªŒ & åç§°è¡¥é½ ============
def validate_and_retry(ref_df: pd.DataFrame):
    # Excel å»é‡åçš„è‚¡ç¥¨åªæ•°
    excel_unique = ref_df['sec_code'].nunique()
    with engine.begin() as conn:
        db_unique = conn.execute(text("SELECT COUNT(*) FROM ref_list")).scalar()
    ok = (excel_unique == db_unique)
    print(f"ğŸ” æ ¡éªŒ Aè¡¨è‚¡ç¥¨åªæ•°ï¼šExcelå»é‡={excel_unique} vs Aè¡¨={db_unique} -> {'OK' if ok else 'MISMATCH'}")

    # æŸ¥æ‰¾ Aè¡¨ä¸­åç§°ä¸ºç©ºæˆ–ç©ºä¸²çš„è‚¡ç¥¨
    with engine.begin() as conn:
        df_missing = pd.read_sql(
            text("SELECT sec_code FROM ref_list WHERE sec_name IS NULL OR sec_name=''"),
            conn
        )
    if df_missing.empty:
        print("ğŸ” Aè¡¨åç§°åˆ—ï¼šæ— ç©ºæ•°æ® âœ…")
        return

    print(f"ğŸ” Aè¡¨åç§°åˆ—ï¼šå‘ç° {len(df_missing)} æ¡ä¸ºç©ºï¼Œå°è¯•é‡è¯•æ‹‰å–å¹¶å›å¡«â€¦â€¦")
    # é‡è¯•è·å–å¹¶å›å¡« A/B è¡¨
    to_fix = df_missing['sec_code'].tolist()
    with engine.begin() as conn:
        upsert_b = text("""
            INSERT INTO stock_info (sec_code, sec_name, float_mktcap_100m)
            VALUES (:sec, :name, :cap)
            ON CONFLICT (sec_code) DO UPDATE
            SET sec_name = COALESCE(EXCLUDED.sec_name, stock_info.sec_name),
                float_mktcap_100m = COALESCE(EXCLUDED.float_mktcap_100m, stock_info.float_mktcap_100m),
                updated_at = NOW();
        """)
        update_a = text("""
            UPDATE ref_list
               SET sec_name = :name, updated_at = NOW()
             WHERE sec_code = :sec;
        """)

        for sec in to_fix:
            name, cap = fetch_name_mktcap(ak_symbol(sec), max_retry=4, sleep_sec=0.8)
            if name:
                conn.execute(upsert_b, {'sec': sec, 'name': name, 'cap': cap})
                conn.execute(update_a, {'sec': sec, 'name': name})

    # å†æ¬¡ç¡®è®¤
    with engine.begin() as conn:
        left = conn.execute(text("SELECT COUNT(*) FROM ref_list WHERE sec_name IS NULL OR sec_name=''")).scalar()
    print(f"ğŸ” åç§°è¡¥é½åå‰©ä½™ç©ºå€¼ï¼š{left} æ¡")

# ============ ä¸»æµç¨‹ ============
def main():
    if len(sys.argv) < 2:
        print("ç”¨æ³•ï¼špython reset_and_load.py <ä½ çš„Excelæˆ–CSVè·¯å¾„>")
        print("ç¤ºä¾‹ï¼špython reset_and_load.py guruList.xlsx")
        sys.exit(1)

    excel_path = sys.argv[1]
    ensure_tables()

    # è¯»å–ä¸è§„èŒƒåŒ–
    df_picks = read_picks(excel_path)

    # åˆ†æ®µ -> A è¡¨
    ref_df = build_ref_list(df_picks)

    # å¡« B è¡¨ï¼ˆåç§°&å¸‚å€¼ï¼‰ï¼Œåç§°å›å¡« A è¡¨
    ref_df = fill_names_and_mktcap(ref_df)

    # å†™ A è¡¨
    save_ref_list(ref_df)

    # ç”¨ A è¡¨â€œæ¯æ®µé¦–æ—¥â€ç”Ÿæˆ C è¡¨çª—å£ï¼ˆæŒ‰äº¤æ˜“æ—¥ç´¢å¼•ï¼‰
    fill_stock_window_from_ref(ref_df)

    # è¿è¡Œå®Œæˆï¼šè‡ªæ£€ & åç§°é‡è¯•è¡¥é½
    validate_and_retry(ref_df)

    # æœ€åç»™ä¸ªæ€»ä½“ç»Ÿè®¡
    with engine.begin() as conn:
        n_a = conn.execute(text("SELECT COUNT(*) FROM ref_list")).scalar()
        n_b = conn.execute(text("SELECT COUNT(*) FROM stock_info")).scalar()
        n_c = conn.execute(text("SELECT COUNT(*) FROM stock_window")).scalar()
    print(f"ğŸ“¦ å¯¼å…¥å®Œæˆï¼šA(ref_list)={n_a} åªï¼ŒB(stock_info)={n_b} æ¡ï¼ŒC(stock_window)={n_c} è¡Œ")

if __name__ == "__main__":
    main()
