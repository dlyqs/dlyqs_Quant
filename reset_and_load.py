import os
import sys
import re
import time
import argparse
import datetime as dt
import pandas as pd
from sqlalchemy import create_engine, text
from dotenv import load_dotenv
from tqdm import tqdm

# éœ€è¦ï¼šakshare, pandas, sqlalchemy, psycopg2-binary, python-dotenv, openpyxl, tqdm
import akshare as ak

# ================== ç¯å¢ƒä¸è¿æ¥ ==================
load_dotenv()
DB_URL = os.getenv("DB_URL")
if not DB_URL:
    print("è¯·åœ¨ .env é‡Œè®¾ç½® DB_URL")
    sys.exit(1)

engine = create_engine(DB_URL, future=True)

# ================== å·¥å…·ï¼šä»£ç ä¸æ—¥æœŸ ==================
DIGITS6 = re.compile(r"^\d{1,6}$")

def fix_code_to_6digits(raw: str) -> str | None:
    """
    ç»Ÿä¸€æˆ 6 ä½æ•°å­—ï¼š000001/300XXX/603XXX/688XXX/8XXXXX ç­‰
    """
    s = str(raw).strip().upper().replace('.SZSE','').replace('.SSE','').replace('.SH','').replace('.SZ','').replace('.BJ','')
    digits = re.sub(r"\D", "", s)
    if not digits or not DIGITS6.match(digits):
        return None
    return digits.zfill(6)

def parse_date(s: str) -> dt.date:
    s = str(s).strip().replace('/','-').replace('.','-')
    return dt.datetime.strptime(s, "%Y-%m-%d").date()

def board_from_code(code6: str) -> str:
    """
    äº¤æ˜“æ¿å—åˆ†ç±»ï¼ˆä¸åŒºåˆ†æ²ª/æ·±ä¸»æ¿ï¼‰ï¼š
      ä¸»æ¿ï¼š600/601/603/605/000/001/002ï¼ˆå«åŸä¸­å°æ¿ï¼‰
      åˆ›ä¸šæ¿ï¼š300
      ç§‘åˆ›æ¿ï¼š688
      åŒ—äº¤æ‰€ï¼š4xxxxx/8xxxxxï¼ˆå¸¸è§ä»¥ 83/87/88 å¼€å¤´ï¼Œç»Ÿä¸€å½’â€œåŒ—äº¤æ‰€â€ï¼‰
    """
    if code6.startswith(("300",)): return "åˆ›ä¸šæ¿"
    if code6.startswith(("688",)): return "ç§‘åˆ›æ¿"
    if code6[0] in ("4","8"):      return "åŒ—äº¤æ‰€"
    if code6.startswith(("600","601","603","605","000","001","002")): return "ä¸»æ¿"
    # å…¶å®ƒéå¸¸è§å‰ç¼€ï¼Œä¿å®ˆæŒ‰ä¸»æ¿å¤„ç†
    return "ä¸»æ¿"

def exch_suffix(code6: str) -> str:
    """æŠŠ 6 ä½ä»£ç æ˜ å°„æˆ .SH/.SZ/.BJ åç¼€ï¼ˆç”¨äºè¡Œæƒ…æ¥å£ fallbackï¼‰"""
    if code6.startswith('6'):       return f"{code6}.SH"
    if code6.startswith(('0','3')): return f"{code6}.SZ"
    if code6.startswith(('4','8')): return f"{code6}.BJ"
    return f"{code6}.SZ"

# ================== å»ºè¡¨ DDL ==================
DDL = """
CREATE TABLE IF NOT EXISTS ref_list (
  sec_code   VARCHAR(6)  PRIMARY KEY,  -- çº¯6ä½ä»£ç 
  board      VARCHAR(10),              -- ä¸»æ¿/åˆ›ä¸šæ¿/ç§‘åˆ›æ¿/åŒ—äº¤æ‰€
  sec_name   VARCHAR(64),
  pick_dates TEXT NOT NULL,            -- æ¯æ®µâ€œé¦–ä¸ªå…¥é€‰æ—¥â€ï¼Œé€—å·åˆ†éš”
  streaks    TEXT,                     -- ä¸ pick_dates å¯¹åº”çš„æ®µå†…è¿ç»­å¤©æ•°
  updated_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE IF NOT EXISTS stock_info (
  sec_code            VARCHAR(6) PRIMARY KEY,
  sec_name            VARCHAR(64) NOT NULL,
  industry            VARCHAR(64),
  float_mktcap_100m   NUMERIC(20,2),
  updated_at          TIMESTAMP DEFAULT NOW()
);

-- ç‰¹å¾è¡¨ï¼šå…¥é€‰æ—¥å‰ T-3~-1 + å…¥é€‰å½“æ—¥ T0 ï¼ˆå…±4å¤©*5æŒ‡æ ‡ï¼‰
CREATE TABLE IF NOT EXISTS stock_pre (
  sec_code  VARCHAR(6) NOT NULL,
  pick_date DATE NOT NULL,
  pctc_m3 NUMERIC(10,4), pcto_m3 NUMERIC(10,4), amp_m3 NUMERIC(10,4), turn_m3 NUMERIC(10,4), amt_m3 NUMERIC(20,2),
  pctc_m2 NUMERIC(10,4), pcto_m2 NUMERIC(10,4), amp_m2 NUMERIC(10,4), turn_m2 NUMERIC(10,4), amt_m2 NUMERIC(20,2),
  pctc_m1 NUMERIC(10,4), pcto_m1 NUMERIC(10,4), amp_m1 NUMERIC(10,4), turn_m1 NUMERIC(10,4), amt_m1 NUMERIC(20,2),
  pctc_d0 NUMERIC(10,4), pcto_d0 NUMERIC(10,4), amp_d0 NUMERIC(10,4), turn_d0 NUMERIC(10,4), amt_d0 NUMERIC(20,2),
  updated_at TIMESTAMP DEFAULT NOW(),
  PRIMARY KEY (sec_code, pick_date)
);

CREATE TABLE IF NOT EXISTS stock_post (
  sec_code  VARCHAR(6) NOT NULL,
  pick_date DATE NOT NULL,
  pctc_p1 NUMERIC(10,4), pcto_p1 NUMERIC(10,4), amp_p1 NUMERIC(10,4),
  pctc_p2 NUMERIC(10,4), pcto_p2 NUMERIC(10,4), amp_p2 NUMERIC(10,4),
  pctc_p3 NUMERIC(10,4), pcto_p3 NUMERIC(10,4), amp_p3 NUMERIC(10,4),
  pctc_p4 NUMERIC(10,4), pcto_p4 NUMERIC(10,4), amp_p4 NUMERIC(10,4),
  pctc_p5 NUMERIC(10,4), pcto_p5 NUMERIC(10,4), amp_p5 NUMERIC(10,4),
  pctc_p6 NUMERIC(10,4), pcto_p6 NUMERIC(10,4), amp_p6 NUMERIC(10,4),
  pctc_p7 NUMERIC(10,4), pcto_p7 NUMERIC(10,4), amp_p7 NUMERIC(10,4),
  updated_at TIMESTAMP DEFAULT NOW(),
  PRIMARY KEY (sec_code, pick_date)
);

-- ç”¨æˆ·å…³æ³¨æŒ‡æ•°çƒ­åº¦è¡¨
CREATE TABLE IF NOT EXISTS stock_heat (
  sec_code  VARCHAR(6) NOT NULL,
  pick_date DATE NOT NULL,
  heat_m5 NUMERIC(10,2), heat_m4 NUMERIC(10,2), heat_m3 NUMERIC(10,2), 
  heat_m2 NUMERIC(10,2), heat_m1 NUMERIC(10,2), heat_d0 NUMERIC(10,2),
  updated_at TIMESTAMP DEFAULT NOW(),
  PRIMARY KEY (sec_code, pick_date)
);

-- æ•£æˆ·æ¯”ä¾‹è¡¨
CREATE TABLE IF NOT EXISTS stock_retail (
  sec_code  VARCHAR(6) NOT NULL,
  pick_date DATE NOT NULL,
  retail_m5 NUMERIC(10,4), retail_m4 NUMERIC(10,4), retail_m3 NUMERIC(10,4),
  retail_m2 NUMERIC(10,4), retail_m1 NUMERIC(10,4), retail_d0 NUMERIC(10,4),
  updated_at TIMESTAMP DEFAULT NOW(),
  PRIMARY KEY (sec_code, pick_date)
);

CREATE INDEX IF NOT EXISTS idx_pre_date  ON stock_pre(pick_date);
CREATE INDEX IF NOT EXISTS idx_post_date ON stock_post(pick_date);
CREATE INDEX IF NOT EXISTS idx_heat_date ON stock_heat(pick_date);
CREATE INDEX IF NOT EXISTS idx_retail_date ON stock_retail(pick_date);
"""

def drop_all_tables():
    with engine.begin() as conn:
        conn.execute(text("DROP SCHEMA public CASCADE;"))
        conn.execute(text("CREATE SCHEMA public;"))
        conn.execute(text("GRANT ALL ON SCHEMA public TO public;"))
        conn.execute(text(DDL))
    print("ğŸ§¨ å·²é”€æ¯å¹¶é‡å»ºæ‰€æœ‰è¡¨ç»“æ„")

def truncate_all_data():
    with engine.begin() as conn:
        for t in ["stock_pre","stock_post","stock_info","ref_list","stock_heat","stock_retail"]:
            conn.execute(text(f"TRUNCATE TABLE {t} RESTART IDENTITY CASCADE;"))
    print("ğŸ§¹ å·²æ¸…ç©ºæ‰€æœ‰è¡¨æ•°æ®ï¼ˆä¿ç•™ç»“æ„ï¼‰")

def ensure_tables():
    with engine.begin() as conn:
        conn.execute(text(DDL))

# ================== è¯»å– Excel & åˆ†æ®µ ==================
def read_picks(excel_path: str) -> pd.DataFrame:
    if excel_path.lower().endswith('.csv'):
        df = pd.read_csv(excel_path)
    else:
        df = pd.read_excel(excel_path)
    df.columns = [c.strip().lower() for c in df.columns]
    if not {'pick_date','code'}.issubset(df.columns):
        raise ValueError("Excel/CSV éœ€åŒ…å«åˆ—ï¼špick_date, code")

    df['sec_code']  = df['code'].apply(fix_code_to_6digits)
    df['pick_date'] = df['pick_date'].apply(parse_date)

    bad = df[df['sec_code'].isna()]
    if not bad.empty:
        print("âš ï¸ å‘ç°æ— æ•ˆä»£ç ï¼ˆå·²è·³è¿‡ï¼‰ï¼š", len(bad))
        print("ç¤ºä¾‹ï¼š", bad.head(5).to_dict(orient='records'))

    df = df[df['sec_code'].notna()]
    df = df[['sec_code','pick_date']].drop_duplicates().sort_values(['sec_code','pick_date'])
    return df

def episodes_from_dates(dates: list[dt.date]) -> tuple[list[dt.date], list[int]]:
    if not dates: return [], []
    starts, streaks = [], []
    cur_start, cur_len = dates[0], 1
    prev = dates[0]
    for d in dates[1:]:
        if (d - prev).days <= 7:
            cur_len += 1
        else:
            starts.append(cur_start); streaks.append(cur_len)
            cur_start, cur_len = d, 1
        prev = d
    starts.append(cur_start); streaks.append(cur_len)
    return starts, streaks

def build_ref_list(df_picks: pd.DataFrame) -> pd.DataFrame:
    rows = []
    for sec, g in df_picks.groupby('sec_code'):
        ds = sorted(g['pick_date'].tolist())
        starts, streaks = episodes_from_dates(ds)
        rows.append({
            'sec_code': sec,
            'board': board_from_code(sec),
            'sec_name': None,
            'pick_dates': ','.join(d.strftime('%Y-%m-%d') for d in starts),
            'streaks': ','.join(str(x) for x in streaks)
        })
    return pd.DataFrame(rows)

# ================== è·å–çƒ­åº¦/æœºæ„å‚ä¸åº¦/è¡Œä¸š ==================
def fetch_heat_data(sec_code: str, max_retry: int = 3, sleep_sec: float = 0.6) -> pd.DataFrame:
    """è·å–ç”¨æˆ·å…³æ³¨æŒ‡æ•°çƒ­åº¦æ•°æ®"""
    last_err = None
    for _ in range(max_retry):
        try:
            df = ak.stock_comment_detail_scrd_focus_em(symbol=sec_code)
            if isinstance(df, pd.DataFrame) and not df.empty:
                df = df.copy()
                df.columns = ['trade_date', 'heat_value']
                df['trade_date'] = pd.to_datetime(df['trade_date']).dt.date
                return df.sort_values('trade_date')
            return pd.DataFrame()
        except Exception as e:
            last_err = e
            time.sleep(sleep_sec)
    if last_err:
        print(f"[{sec_code}] è·å–çƒ­åº¦æ•°æ®å¤±è´¥ï¼š{last_err}")
    return pd.DataFrame()

def fetch_retail_data(sec_code: str, max_retry: int = 3, sleep_sec: float = 0.6) -> pd.DataFrame:
    """è·å–æœºæ„å‚ä¸åº¦æ•°æ®å¹¶è®¡ç®—æ•£æˆ·æ¯”ä¾‹"""
    last_err = None
    for _ in range(max_retry):
        try:
            df = ak.stock_comment_detail_zlkp_jgcyd_em(symbol=sec_code)
            if isinstance(df, pd.DataFrame) and not df.empty:
                df = df.copy()
                df.columns = ['trade_date', 'institution_rate']
                df['trade_date'] = pd.to_datetime(df['trade_date']).dt.date
                # è®¡ç®—æ•£æˆ·æ¯”ä¾‹ = 100 - æœºæ„å‚ä¸åº¦
                df['retail_rate'] = 100.0 - df['institution_rate']
                return df.sort_values('trade_date')
            return pd.DataFrame()
        except Exception as e:
            last_err = e
            time.sleep(sleep_sec)
    if last_err:
        print(f"[{sec_code}] è·å–æœºæ„å‚ä¸åº¦æ•°æ®å¤±è´¥ï¼š{last_err}")
    return pd.DataFrame()

def fetch_industry_info(sec_code: str, max_retry: int = 3, sleep_sec: float = 0.6) -> str | None:
    """è·å–è¡Œä¸šä¿¡æ¯"""
    last_err = None
    for _ in range(max_retry):
        try:
            df = ak.stock_individual_info_em(sec_code)
            if isinstance(df, pd.DataFrame) and not df.empty:
                item_col, val_col = df.columns[:2]
                row = df[df[item_col].astype(str).str.contains("è¡Œä¸š", na=False)]
                if not row.empty:
                    industry = str(row.iloc[0, 1]).strip()
                    return industry if industry and industry != "None" else None
            return None
        except Exception as e:
            last_err = e
            time.sleep(sleep_sec)
    if last_err:
        print(f"[{sec_code}] è·å–è¡Œä¸šä¿¡æ¯å¤±è´¥ï¼š{last_err}")
    return None

# ================== åç§°/å¸‚å€¼ï¼ˆå¸¦é‡è¯•ï¼‰ ==================
def fetch_name_mktcap(sym: str, max_retry: int = 3, sleep_sec: float = 0.6):
    last_err = None
    for _ in range(max_retry):
        try:
            info = ak.stock_individual_info_em(sym)  # sym = '603123'
            if isinstance(info, pd.DataFrame) and not info.empty and info.shape[1] >= 2:
                info = info.iloc[:, :2].copy()
                info.columns = ['item','value']
                kv = dict(zip(info['item'], info['value']))
                name = kv.get('è¯åˆ¸ç®€ç§°') or kv.get('è‚¡ç¥¨ç®€ç§°') or kv.get('ç®€ç§°')
                v = kv.get('æµé€šå¸‚å€¼(å…ƒ)') or kv.get('æµé€šå¸‚å€¼')
                if isinstance(v, str):
                    v = float(v.replace(',', '').replace('å…ƒ','').strip() or 0)
                cap100m = (v/1e8) if v else None
                return name, cap100m
            return None, None
        except Exception as e:
            last_err = e
            time.sleep(sleep_sec)
    if last_err:
        print(f"[{sym}] è·å–åç§°/å¸‚å€¼å¤±è´¥ï¼š{last_err}")
    return None, None

def upsert_stock_info(sec_code: str, sec_name: str | None, cap100m: float | None, industry: str | None = None):
    with engine.begin() as conn:
        conn.execute(text("""
            INSERT INTO stock_info (sec_code, sec_name, industry, float_mktcap_100m)
            VALUES (:sec, :name, :industry, :cap)
            ON CONFLICT (sec_code) DO UPDATE
            SET sec_name = COALESCE(EXCLUDED.sec_name, stock_info.sec_name),
                industry = COALESCE(EXCLUDED.industry, stock_info.industry),
                float_mktcap_100m = COALESCE(EXCLUDED.float_mktcap_100m, stock_info.float_mktcap_100m),
                updated_at = NOW();
        """), {'sec': sec_code, 'name': (sec_name or ''), 'industry': industry, 'cap': cap100m})

def fill_names_and_mktcap(ref_df: pd.DataFrame) -> pd.DataFrame:
    names, caps, industries = [], [], []
    print("ğŸ“Š æ­£åœ¨è·å–è‚¡ç¥¨åç§°ã€å¸‚å€¼å’Œè¡Œä¸šä¿¡æ¯...")
    for sec in tqdm(ref_df['sec_code'], desc="è·å–è‚¡ç¥¨ä¿¡æ¯", unit="åª"):
        name, cap = fetch_name_mktcap(sec)  # ä¼  6ä½æ•°å­—å³å¯
        industry = fetch_industry_info(sec)  # è·å–è¡Œä¸šä¿¡æ¯
        names.append(name); caps.append(cap); industries.append(industry)
        upsert_stock_info(sec, name, cap, industry)
    ref_df = ref_df.copy()
    ref_df['sec_name'] = names
    return ref_df

def save_ref_list(ref_df: pd.DataFrame):
    with engine.begin() as conn:
        upsert = text("""
            INSERT INTO ref_list (sec_code, board, sec_name, pick_dates, streaks)
            VALUES (:sec, :board, :name, :dates, :streaks)
            ON CONFLICT (sec_code) DO UPDATE
            SET board = EXCLUDED.board,
                sec_name = COALESCE(EXCLUDED.sec_name, ref_list.sec_name),
                pick_dates = EXCLUDED.pick_dates,
                streaks = EXCLUDED.streaks,
                updated_at = NOW();
        """)
        for _, r in ref_df.iterrows():
            conn.execute(upsert, {
                'sec': r['sec_code'],
                'board': r['board'],
                'name': r['sec_name'] if pd.notna(r['sec_name']) else None,
                'dates': r['pick_dates'],
                'streaks': r['streaks']
            })
    print(f"âœ… å·²å†™å…¥ Aè¡¨ ref_listï¼š{len(ref_df)} åª")

# ================== è¡Œæƒ…ï¼šäº¤æ˜“æ—¥ç´¢å¼• ==================
def fetch_hist_df(sec_code: str, start: dt.date, end: dt.date) -> pd.DataFrame:
    """
    ä½¿ç”¨akshareè·å–è‚¡ç¥¨å†å²æ•°æ®
    å°è¯•å¤šç§æ–¹æ³•ï¼š
      1) ak.stock_zh_a_daily(ä¸å¤æƒç‰ˆæœ¬ï¼Œç¨³å®šå¯ç”¨)
      2) ak.stock_zh_a_hist(6ä½æ•°å­—ï¼Œå¤‡é€‰)
    """
    s = start.strftime("%Y%m%d")
    e = end.strftime("%Y%m%d")

    # è·¯çº¿1ï¼šstock_zh_a_dailyï¼ˆæ–°ç‰ˆæœ¬æ¨èï¼Œæœ€ç¨³å®šï¼‰
    try:
        # ç”Ÿæˆæ­£ç¡®çš„symbolæ ¼å¼
        if sec_code.startswith('6'):
            symbol = f"sh{sec_code}"  # æ²ªå¸‚
        elif sec_code.startswith(('0', '3')):
            symbol = f"sz{sec_code}"  # æ·±å¸‚
        elif sec_code.startswith(('4', '8')):
            symbol = f"bj{sec_code}"  # åŒ—äº¤æ‰€ï¼ˆå¦‚æœæ”¯æŒï¼‰
        else:
            symbol = f"sz{sec_code}"  # é»˜è®¤æ·±å¸‚
            
        df = ak.stock_zh_a_daily(symbol=symbol, start_date=s, end_date=e, adjust="")
        if isinstance(df, pd.DataFrame) and not df.empty:
            # æˆåŠŸè·å–æ•°æ®ï¼Œè·³è½¬åˆ°æ•°æ®å¤„ç†éƒ¨åˆ†
            pass
        else:
            df = None
    except Exception as e:
        # print(f"[{sec_code}] stock_zh_a_dailyå¤±è´¥: {e}")
        df = None

    # è·¯çº¿2ï¼šstock_zh_a_histï¼ˆ6ä½æ•°å­—ï¼Œå¤‡é€‰ï¼‰
    if df is None:
        try:
            df = ak.stock_zh_a_hist(symbol=sec_code, period="daily", start_date=s, end_date=e, adjust="qfq")
            if isinstance(df, pd.DataFrame) and not df.empty:
                pass
            else:
                df = None
        except Exception as e:
            # print(f"[{sec_code}] stock_zh_a_histå¤±è´¥: {e}")
            df = None

    # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥
    if df is None or not isinstance(df, pd.DataFrame) or df.empty:
        return pd.DataFrame()

    # ç»Ÿä¸€åˆ—åå¤„ç†
    mapping = {
        # stock_zh_a_dailyçš„åˆ—å
        "date":"date","open":"open","high":"high","low":"low","close":"close",
        "volume":"volume","amount":"amount","outstanding_share":"outstanding_share","turnover":"turnover_rate",
        # stock_zh_a_histçš„ä¸­æ–‡åˆ—å
        "æ—¥æœŸ":"date","å¼€ç›˜":"open","æœ€é«˜":"high","æœ€ä½":"low","æ”¶ç›˜":"close",
        "æ¶¨è·Œå¹…":"pct_chg","æŒ¯å¹…":"amplitude","æˆäº¤é‡":"volume","æˆäº¤é¢":"amount",
        "æ¢æ‰‹ç‡":"turnover_rate","é‡æ¯”":"volume_ratio","å‰æ”¶ç›˜":"pre_close",
        # å…¶ä»–å¯èƒ½çš„åˆ—å
        "change_pct":"pct_chg","preclose":"pre_close"
    }
    
    # é‡å‘½ååˆ—
    cols = {c: mapping.get(c, c) for c in df.columns}
    df = df.rename(columns=cols).copy()

    # ç¡®ä¿æ—¥æœŸåˆ—æ ¼å¼æ­£ç¡®
    df["date"] = pd.to_datetime(df["date"], errors="coerce").dt.date
    df = df[pd.notna(df["date"])].sort_values("date")
    if df.empty: 
        return pd.DataFrame()

    # è®¡ç®—å¿…éœ€çš„æŠ€æœ¯æŒ‡æ ‡
    # å‰æ”¶ç›˜ä»·
    if "pre_close" not in df.columns or df["pre_close"].isna().all():
        df["pre_close"] = df["close"].shift(1)
    
    # æ¶¨è·Œå¹…ï¼ˆç™¾åˆ†æ¯”ï¼‰
    if "pct_chg" not in df.columns or df["pct_chg"].isna().all():
        df["pct_chg"] = (df["close"] / df["pre_close"] - 1.0) * 100
    
    # æŒ¯å¹…ï¼ˆç™¾åˆ†æ¯”ï¼‰
    if "amplitude" not in df.columns or df["amplitude"].isna().all():
        df["amplitude"] = (df["high"] - df["low"]) / df["pre_close"] * 100
    
    # ç¡®ä¿æ¢æ‰‹ç‡åˆ—å­˜åœ¨
    if "turnover_rate" not in df.columns:
        if "turnover" in df.columns:
            df["turnover_rate"] = df["turnover"]
        else:
            df["turnover_rate"] = None
    
    # å¼€ç›˜æ¶¨è·Œå¹…
    df["pcto"] = (df["open"] / df["pre_close"] - 1.0) * 100
    
    return df

def pick_by_trade_offset(hist: pd.DataFrame, t: dt.date, delta: int):
    """
    åœ¨ hist çš„äº¤æ˜“æ—¥åºåˆ—é‡Œï¼šä»¥â€œæœ€è¿‘ä¸æ™šäº t çš„äº¤æ˜“æ—¥â€ä¸ºåŸºå‡†ï¼Œå†å–åç§» deltaã€‚
    è¿™æ · Excel ç»™åˆ°å‘¨æœ«/èŠ‚å‡æ—¥æ—¶ä¸ä¼šæ•´æ®µå¤±é…ã€‚
    è¿”å›ï¼špctc, pcto, amp, turn, amt
    """
    if hist is None or hist.empty:
        return (None, None, None, None, None)

    dates = hist["date"].tolist()
    # æ‰¾åˆ° <= t çš„æœ€è¿‘ä¸€ä¸ªäº¤æ˜“æ—¥ä¸‹æ ‡
    i = None
    # å¿«é€ŸäºŒåˆ†ä¹Ÿè¡Œï¼Œè¿™é‡Œç”¨çº¿æ€§å›é€€æ˜“è¯»
    for k in range(len(dates)-1, -1, -1):
        if dates[k] <= t:
            i = k
            break
    if i is None:
        return (None, None, None, None, None)

    j = i + delta
    if j < 0 or j >= len(dates):
        return (None, None, None, None, None)

    r = hist.iloc[j]
    return (
        float(r.get('pct_chg')) if pd.notna(r.get('pct_chg')) else None,
        float(r.get('pcto'))    if pd.notna(r.get('pcto'))    else None,
        float(r.get('amplitude')) if pd.notna(r.get('amplitude')) else None,
        float(r.get('turnover_rate')) if pd.notna(r.get('turnover_rate')) else None,
        float(r.get('amount'))  if pd.notna(r.get('amount'))  else None,
    )

def pick_by_date_offset(data_df: pd.DataFrame, target_date: dt.date, delta: int, value_col: str):
    """
    ä»æ—¶é—´åºåˆ—æ•°æ®ä¸­è·å–ç›®æ ‡æ—¥æœŸåç§»deltaå¤©çš„å€¼
    """
    if data_df is None or data_df.empty:
        return None
    
    dates = data_df["trade_date"].tolist()
    # æ‰¾åˆ° <= target_date çš„æœ€è¿‘ä¸€ä¸ªäº¤æ˜“æ—¥ä¸‹æ ‡
    i = None
    for k in range(len(dates)-1, -1, -1):
        if dates[k] <= target_date:
            i = k
            break
    if i is None:
        return None
    
    j = i + delta
    if j < 0 or j >= len(dates):
        return None
    
    r = data_df.iloc[j]
    val = r.get(value_col)
    return float(val) if pd.notna(val) else None

# ================== å†™å…¥ï¼šstock_pre / stock_post / stock_heat / stock_retail ==================
def upsert_pre_row(conn, sec: str, t: dt.date, hist: pd.DataFrame):
    payload = {'sec': sec, 't': t}
    for suf, delta in [('m3',-3),('m2',-2),('m1',-1),('d0',0)]:
        pctc, pcto, amp, turn, amt = pick_by_trade_offset(hist, t, delta)
        payload[f"pctc_{suf}"]=pctc; payload[f"pcto_{suf}"]=pcto
        payload[f"amp_{suf}"]=amp;   payload[f"turn_{suf}"]=turn; payload[f"amt_{suf}"]=amt

    conn.execute(text("""
        INSERT INTO stock_pre (
          sec_code, pick_date,
          pctc_m3,pcto_m3,amp_m3,turn_m3,amt_m3,
          pctc_m2,pcto_m2,amp_m2,turn_m2,amt_m2,
          pctc_m1,pcto_m1,amp_m1,turn_m1,amt_m1,
          pctc_d0,pcto_d0,amp_d0,turn_d0,amt_d0
        ) VALUES (
          :sec, :t,
          :pctc_m3,:pcto_m3,:amp_m3,:turn_m3,:amt_m3,
          :pctc_m2,:pcto_m2,:amp_m2,:turn_m2,:amt_m2,
          :pctc_m1,:pcto_m1,:amp_m1,:turn_m1,:amt_m1,
          :pctc_d0,:pcto_d0,:amp_d0,:turn_d0,:amt_d0
        )
        ON CONFLICT (sec_code, pick_date) DO UPDATE SET
          pctc_m3=EXCLUDED.pctc_m3, pcto_m3=EXCLUDED.pcto_m3, amp_m3=EXCLUDED.amp_m3, turn_m3=EXCLUDED.turn_m3, amt_m3=EXCLUDED.amt_m3,
          pctc_m2=EXCLUDED.pctc_m2, pcto_m2=EXCLUDED.pcto_m2, amp_m2=EXCLUDED.amp_m2, turn_m2=EXCLUDED.turn_m2, amt_m2=EXCLUDED.amt_m2,
          pctc_m1=EXCLUDED.pctc_m1, pcto_m1=EXCLUDED.pcto_m1, amp_m1=EXCLUDED.amp_m1, turn_m1=EXCLUDED.turn_m1, amt_m1=EXCLUDED.amt_m1,
          pctc_d0=EXCLUDED.pctc_d0, pcto_d0=EXCLUDED.pcto_d0, amp_d0=EXCLUDED.amp_d0, turn_d0=EXCLUDED.turn_d0, amt_d0=EXCLUDED.amt_d0,
          updated_at = NOW();
    """), payload)

def upsert_post_row(conn, sec: str, t: dt.date, hist: pd.DataFrame):
    payload = {'sec': sec, 't': t}
    for k in range(1, 8):  # p1..p7
        pctc, pcto, amp, _, _ = pick_by_trade_offset(hist, t, k)
        payload[f"pctc_p{k}"]=pctc; payload[f"pcto_p{k}"]=pcto; payload[f"amp_p{k}"]=amp

    conn.execute(text("""
        INSERT INTO stock_post (
          sec_code, pick_date,
          pctc_p1,pcto_p1,amp_p1,
          pctc_p2,pcto_p2,amp_p2,
          pctc_p3,pcto_p3,amp_p3,
          pctc_p4,pcto_p4,amp_p4,
          pctc_p5,pcto_p5,amp_p5,
          pctc_p6,pcto_p6,amp_p6,
          pctc_p7,pcto_p7,amp_p7
        ) VALUES (
          :sec, :t,
          :pctc_p1,:pcto_p1,:amp_p1,
          :pctc_p2,:pcto_p2,:amp_p2,
          :pctc_p3,:pcto_p3,:amp_p3,
          :pctc_p4,:pcto_p4,:amp_p4,
          :pctc_p5,:pcto_p5,:amp_p5,
          :pctc_p6,:pcto_p6,:amp_p6,
          :pctc_p7,:pcto_p7,:amp_p7
        )
        ON CONFLICT (sec_code, pick_date) DO UPDATE SET
          pctc_p1=EXCLUDED.pctc_p1, pcto_p1=EXCLUDED.pcto_p1, amp_p1=EXCLUDED.amp_p1,
          pctc_p2=EXCLUDED.pctc_p2, pcto_p2=EXCLUDED.pcto_p2, amp_p2=EXCLUDED.amp_p2,
          pctc_p3=EXCLUDED.pctc_p3, pcto_p3=EXCLUDED.pcto_p3, amp_p3=EXCLUDED.amp_p3,
          pctc_p4=EXCLUDED.pctc_p4, pcto_p4=EXCLUDED.pcto_p4, amp_p4=EXCLUDED.amp_p4,
          pctc_p5=EXCLUDED.pctc_p5, pcto_p5=EXCLUDED.pcto_p5, amp_p5=EXCLUDED.amp_p5,
          pctc_p6=EXCLUDED.pctc_p6, pcto_p6=EXCLUDED.pcto_p6, amp_p6=EXCLUDED.amp_p6,
          pctc_p7=EXCLUDED.pctc_p7, pcto_p7=EXCLUDED.pcto_p7, amp_p7=EXCLUDED.amp_p7,
          updated_at = NOW();
    """), payload)

def upsert_heat_row(conn, sec: str, t: dt.date, heat_df: pd.DataFrame):
    """å†™å…¥çƒ­åº¦æ•°æ®ï¼šå…¥é€‰æ—¥å½“å¤©å’Œå‰5æ—¥"""
    payload = {'sec': sec, 't': t}
    for k in range(-5, 1):  # m5, m4, m3, m2, m1, d0
        suf = f"m{abs(k)}" if k < 0 else "d0"
        heat_val = pick_by_date_offset(heat_df, t, k, 'heat_value')
        payload[f"heat_{suf}"] = heat_val
    
    conn.execute(text("""
        INSERT INTO stock_heat (
          sec_code, pick_date, heat_m5, heat_m4, heat_m3, heat_m2, heat_m1, heat_d0
        ) VALUES (
          :sec, :t, :heat_m5, :heat_m4, :heat_m3, :heat_m2, :heat_m1, :heat_d0
        )
        ON CONFLICT (sec_code, pick_date) DO UPDATE SET
          heat_m5=EXCLUDED.heat_m5, heat_m4=EXCLUDED.heat_m4, heat_m3=EXCLUDED.heat_m3,
          heat_m2=EXCLUDED.heat_m2, heat_m1=EXCLUDED.heat_m1, heat_d0=EXCLUDED.heat_d0,
          updated_at = NOW();
    """), payload)

def upsert_retail_row(conn, sec: str, t: dt.date, retail_df: pd.DataFrame):
    """å†™å…¥æ•£æˆ·æ¯”ä¾‹æ•°æ®ï¼šå…¥é€‰æ—¥å½“å¤©å’Œå‰5æ—¥"""
    payload = {'sec': sec, 't': t}
    for k in range(-5, 1):  # m5, m4, m3, m2, m1, d0
        suf = f"m{abs(k)}" if k < 0 else "d0"
        retail_val = pick_by_date_offset(retail_df, t, k, 'retail_rate')
        payload[f"retail_{suf}"] = retail_val
    
    conn.execute(text("""
        INSERT INTO stock_retail (
          sec_code, pick_date, retail_m5, retail_m4, retail_m3, retail_m2, retail_m1, retail_d0
        ) VALUES (
          :sec, :t, :retail_m5, :retail_m4, :retail_m3, :retail_m2, :retail_m1, :retail_d0
        )
        ON CONFLICT (sec_code, pick_date) DO UPDATE SET
          retail_m5=EXCLUDED.retail_m5, retail_m4=EXCLUDED.retail_m4, retail_m3=EXCLUDED.retail_m3,
          retail_m2=EXCLUDED.retail_m2, retail_m1=EXCLUDED.retail_m1, retail_d0=EXCLUDED.retail_d0,
          updated_at = NOW();
    """), payload)

def fill_windows_for(ref_df: pd.DataFrame, mode: str):
    """
    ä»…å¯¹"æ¯æ®µé¦–æ—¥ pick_date"å†™å…¥ stock_pre/stock_postã€‚
    åœ¨ append æ¨¡å¼ä¸‹ï¼Œåªå¯¹"æœªå­˜åœ¨çš„ (sec_code,pick_date)" è¿½åŠ ï¼›å…¶ä»–æ¨¡å¼å…¨é‡è¦†ç›–ã€‚
    """
    print("ğŸ”„ æ­£åœ¨å‡†å¤‡çª—å£æ•°æ®...")
    
    # ä» ref_dfï¼ˆExcel è®¡ç®—ï¼‰å–å¾—ç›®æ ‡é›†
    targets = []
    for _, r in ref_df.iterrows():
        sec = r['sec_code']
        ep_starts = [dt.datetime.strptime(x.strip(), "%Y-%m-%d").date()
                     for x in str(r['pick_dates']).split(',') if x.strip()]
        for t in ep_starts:
            targets.append((sec, t))
    targets = sorted(set(targets))

    # append æ¨¡å¼ï¼šè¿‡æ»¤æ‰ DB å·²æœ‰çš„ (sec,t)
    if mode == "append":
        with engine.begin() as conn:
            exist_pre = pd.read_sql(text("SELECT sec_code, pick_date FROM stock_pre"), conn)
            exist_post= pd.read_sql(text("SELECT sec_code, pick_date FROM stock_post"), conn)
            exist_heat = pd.read_sql(text("SELECT sec_code, pick_date FROM stock_heat"), conn)
            exist_retail = pd.read_sql(text("SELECT sec_code, pick_date FROM stock_retail"), conn)
        existed = set(map(tuple, exist_pre.values.tolist())) | set(map(tuple, exist_post.values.tolist())) | \
                 set(map(tuple, exist_heat.values.tolist())) | set(map(tuple, exist_retail.values.tolist()))
        targets = [x for x in targets if x not in existed]
        print(f"â• è¿½åŠ æ¨¡å¼ï¼šéœ€è¦æ–°å¢çª—å£ {len(targets)} è¡Œ")

    if not targets:
        print("ğŸ“­ æ— éœ€å†™å…¥çª—å£æ•°æ®")
        return

    # é¢„å–æ¯åªè‚¡ç¥¨å†å²ï¼ˆæŒ‰æœ€å°/æœ€å¤§æ®µé¦–æ—¥æ‰© 40 å¤©ï¼Œè¶³å¤Ÿè¦†ç›– m3~p7ï¼‰
    groups = {}
    for sec, t in targets:
        info = groups.get(sec, {'min':t, 'max':t})
        info['min'] = min(info['min'], t)
        info['max'] = max(info['max'], t)
        groups[sec] = info

    print(f"ğŸ“ˆ æ­£åœ¨è·å– {len(groups)} åªè‚¡ç¥¨çš„å†å²æ•°æ®å¹¶å†™å…¥çª—å£...")
    
    with engine.begin() as conn:
        for sec, span in tqdm(groups.items(), desc="å¤„ç†è‚¡ç¥¨å†å²æ•°æ®", unit="åª"):
            start = span['min'] - dt.timedelta(days=40)
            end   = span['max'] + dt.timedelta(days=40)
            
            # è·å–å†å²è¡Œæƒ…æ•°æ®
            hist = fetch_hist_df(sec, start, end)
            
            # è·å–çƒ­åº¦æ•°æ®
            heat_df = fetch_heat_data(sec)
            
            # è·å–æ•£æˆ·æ¯”ä¾‹æ•°æ®
            retail_df = fetch_retail_data(sec)
            
            if hist.empty:
                tqdm.write(f"[{sec}] æ— å†å²æ•°æ®ï¼Œè·³è¿‡")
                continue

            # é’ˆå¯¹è¯¥ sec çš„æ‰€æœ‰ç›®æ ‡æ—¥å†™å…¥
            target_dates = [x for x in targets if x[0]==sec]
            for (s, t) in target_dates:
                upsert_pre_row(conn, sec, t, hist)
                upsert_post_row(conn, sec, t, hist)
                upsert_heat_row(conn, sec, t, heat_df)
                upsert_retail_row(conn, sec, t, retail_df)

    print("âœ… å·²å†™å…¥ stock_pre / stock_post / stock_heat / stock_retail")

# ================== è¿è¡Œåæ ¡éªŒ & åç§°è¡¥é½ ==================
def validate_and_retry(ref_df: pd.DataFrame):
    print("ğŸ” æ­£åœ¨æ ¡éªŒæ•°æ®å®Œæ•´æ€§...")
    excel_unique = ref_df['sec_code'].nunique()
    with engine.begin() as conn:
        db_unique = conn.execute(text("SELECT COUNT(*) FROM ref_list")).scalar()
    print(f"ğŸ” æ ¡éªŒ Aè¡¨è‚¡ç¥¨åªæ•°ï¼šExcelå»é‡={excel_unique} vs Aè¡¨={db_unique} -> {'OK' if excel_unique==db_unique else 'MISMATCH'}")

    with engine.begin() as conn:
        df_missing = pd.read_sql(text("SELECT sec_code FROM ref_list WHERE sec_name IS NULL OR sec_name=''"), conn)
    if df_missing.empty:
        print("ğŸ” Aè¡¨åç§°åˆ—ï¼šæ— ç©ºæ•°æ® âœ…")
        return

    print(f"ğŸ” Aè¡¨åç§°åˆ—ï¼šå‘ç° {len(df_missing)} æ¡ä¸ºç©ºï¼Œé‡è¯•å›å¡«â€¦â€¦")
    with engine.begin() as conn:
        update_a = text("UPDATE ref_list SET sec_name=:name, updated_at=NOW() WHERE sec_code=:sec;")
        for sec in tqdm(df_missing['sec_code'].tolist(), desc="è¡¥é½è‚¡ç¥¨åç§°", unit="åª"):
            name, cap = fetch_name_mktcap(sec, max_retry=4, sleep_sec=0.8)
            if name:
                upsert_stock_info(sec, name, cap)
                conn.execute(update_a, {'sec': sec, 'name': name})

    with engine.begin() as conn:
        left = conn.execute(text("SELECT COUNT(*) FROM ref_list WHERE sec_name IS NULL OR sec_name=''")).scalar()
    print(f"ğŸ” åç§°è¡¥é½åå‰©ä½™ç©ºå€¼ï¼š{left} æ¡")
    
    # è¡¥é½è¡Œä¸šä¿¡æ¯
    with engine.begin() as conn:
        df_missing_industry = pd.read_sql(text("SELECT sec_code FROM stock_info WHERE industry IS NULL OR industry=''"), conn)
    if not df_missing_industry.empty:
        print(f"ğŸ” Bè¡¨è¡Œä¸šåˆ—ï¼šå‘ç° {len(df_missing_industry)} æ¡ä¸ºç©ºï¼Œé‡è¯•å›å¡«â€¦â€¦")
        with engine.begin() as conn:
            update_industry = text("UPDATE stock_info SET industry=:industry, updated_at=NOW() WHERE sec_code=:sec;")
            for sec in tqdm(df_missing_industry['sec_code'].tolist(), desc="è¡¥é½è¡Œä¸šä¿¡æ¯", unit="åª"):
                industry = fetch_industry_info(sec, max_retry=4, sleep_sec=0.8)
                if industry:
                    conn.execute(update_industry, {'sec': sec, 'industry': industry})
    else:
        print("ğŸ” Bè¡¨è¡Œä¸šåˆ—ï¼šæ— ç©ºæ•°æ® âœ…")


# ================== ä¸»æµç¨‹ ==================
def main():
    parser = argparse.ArgumentParser(description="Load GuruList into PostgreSQL")
    parser.add_argument("excel", help="Excel/CSV path, must contain columns: code, pick_date")
    parser.add_argument("--mode", choices=["drop","truncate","append"], default="append",
                        help="drop: é”€æ¯å¹¶é‡å»ºç»“æ„åå…¨é‡å¯¼å…¥ï¼›truncate: æ¸…ç©ºæ•°æ®åå…¨é‡å¯¼å…¥ï¼›append: åªè¿½åŠ Excelä¸­çš„æ–°å¢æ®µé¦–æ—¥ï¼ˆé»˜è®¤ï¼‰")
    args = parser.parse_args()

    print("ğŸš€ å¼€å§‹æ‰§è¡Œ GuruList æ•°æ®åŠ è½½...")
    print(f"ğŸ“„ æ•°æ®æ–‡ä»¶: {args.excel}")
    print(f"âš™ï¸  æ‰§è¡Œæ¨¡å¼: {args.mode}")
    print("-" * 50)

    # æ­¥éª¤1: å‡†å¤‡æ•°æ®åº“è¡¨ç»“æ„
    print("ğŸ“‹ æ­¥éª¤ 1/5: å‡†å¤‡æ•°æ®åº“è¡¨ç»“æ„")
    if args.mode == "drop":
        drop_all_tables()
    else:
        ensure_tables()
        if args.mode == "truncate":
            truncate_all_data()

    # æ­¥éª¤2: è¯»å–å’Œå¤„ç†Excelæ•°æ®
    print("ğŸ“‹ æ­¥éª¤ 2/5: è¯»å–å’Œå¤„ç†Excelæ•°æ®")
    df_picks = read_picks(args.excel)
    ref_df   = build_ref_list(df_picks)
    print(f"âœ… å¤„ç†å®Œæˆï¼Œå…± {len(ref_df)} åªè‚¡ç¥¨")

    # æ­¥éª¤3: è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
    print("ğŸ“‹ æ­¥éª¤ 3/5: è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯")
    ref_df   = fill_names_and_mktcap(ref_df)
    save_ref_list(ref_df)

    # æ­¥éª¤4: è·å–å†å²è¡Œæƒ…æ•°æ®
    print("ğŸ“‹ æ­¥éª¤ 4/5: è·å–å†å²è¡Œæƒ…æ•°æ®")
    fill_windows_for(ref_df, mode=args.mode)

    # æ­¥éª¤5: æ•°æ®æ ¡éªŒå’Œè¡¥é½
    print("ğŸ“‹ æ­¥éª¤ 5/5: æ•°æ®æ ¡éªŒå’Œè¡¥é½")
    validate_and_retry(ref_df)

    # æ±‡æ€»æŠ¥å‘Š
    print("-" * 50)
    print("ğŸ“Š æ•°æ®åŠ è½½å®Œæˆæ±‡æ€»:")
    with engine.begin() as conn:
        n_a = conn.execute(text("SELECT COUNT(*) FROM ref_list")).scalar()
        n_b = conn.execute(text("SELECT COUNT(*) FROM stock_info")).scalar()
        n_pre = conn.execute(text("SELECT COUNT(*) FROM stock_pre")).scalar()
        n_post= conn.execute(text("SELECT COUNT(*) FROM stock_post")).scalar()
        n_heat = conn.execute(text("SELECT COUNT(*) FROM stock_heat")).scalar()
        n_retail = conn.execute(text("SELECT COUNT(*) FROM stock_retail")).scalar()
    print(f"ğŸ“¦ Aè¡¨(ref_list): {n_a} åªè‚¡ç¥¨")
    print(f"ğŸ“¦ Bè¡¨(stock_info): {n_b} æ¡è®°å½•")
    print(f"ğŸ“¦ PREè¡¨(ç‰¹å¾æ•°æ®): {n_pre} è¡Œ")
    print(f"ğŸ“¦ POSTè¡¨(åç»­æ•°æ®): {n_post} è¡Œ")
    print(f"ğŸ“¦ HEATè¡¨(çƒ­åº¦æ•°æ®): {n_heat} è¡Œ")
    print(f"ğŸ“¦ RETAILè¡¨(æ•£æˆ·æ¯”ä¾‹): {n_retail} è¡Œ")
    print("ğŸ‰ å…¨éƒ¨å®Œæˆï¼")

if __name__ == "__main__":
    main()
